{
    "number": 10,
    "title": "Module 10: Introduction to Machine Learning: Perceptrons",
    "sections": [
        {
            "title": "Section 1",
            "colorScheme": "dark",
            "subsections": [
              {
                "title": "Subsection 1",
                "body": "lorem ipsum",
                "imgSrc": "mod10.png"
              },
              {
                "title": "Subsection 2",
                "body": "lorem ipsum",
                "imgSrc": "mod10.png"
              },
              {
                "title": "Subsection 3",
                "body": "lorem ipsum",
                "imgSrc": "mod10.png"
              }
            ]
          },
          {
            "title": "The Perceptron",
            "colorScheme": "light",
            "subsections": [
              {
                "title": "Subsection 1",
                "body": "We previously showed how we can use PCA and clustering to classify data. However, those methods are limited by the dimensions of our data and can only take us so far; how can we perform more reliable classifications on high-dimensional data? The answer is the perceptron.",
                "imgSrc": "/blank.png"
              },
              {
                "title": "Subsection 2",
                "body": "The perceptron is a single-layer neural network that serves as a linear classifier. In other words, it is an algorithm that establishes a binary classification rule for input data. The crux of the perceptron is that certain features of the data are more important (ie weighted more heavily) to the classification.",
                "imgSrc": "/blank.png"
              },
              {
                "title": "Subsection 3",
                "body": "The most simple kind of perceptron is the McCulloch-Pitts Neuron. Data used for this perceptron are of the form of a binary vector; each feature is either activated (value 1) or not (value 0). The MP neuron has two key components; it has weights that it assigns to each of the features, and a threshold value used to determine the classification. It functions by performing a weighted sum of all of the features (the dot product of the input vector and weight vector) and compares the sum to the threshold. The output of the perceptron is a binary value indicating whether the weighted sum meets the threshold (value 1) or doesn't (value 0). To use the MP neuron below, you can change the number of inputs, the weights, and the threshold value (including whether we want > or < ).",
                "imgSrc": "/blank.png"
              }
            ],
            "demoComp": "MPNeuron"
          },
          {
            "title": "",
            "colorScheme": "dark",
            "subsections": [
                {
                    "title": "Subsection 1",
                    "body": "So how does each iteration of this algorithm work to minimize error? The answer is some clever vector math. The animation below demonstrates how this process works as it processes a single point from the input.",
                    "imgSrc": "/blank.png"
                },
                {
                    "title": "Subsection 2",
                    "body": "We can think of the line dividing our two input groups as represented by a vector Wt; that is, given a vector, you can always draw a line perpendicular to where it starts. When the algorithm encounters a point that has been misclassified, it finds the vector representing the distance, d, between that point our dividing line. To update the dividing line, we subtract d from Wt. This new vector corresponds to a new perpendicular line, which forms a more accurate division between the inputs.",
                    "imgSrc": "/blank.png"
                }
            ],
            "demoComp": "RblattVectorsDemo"
        }
    ]
}
