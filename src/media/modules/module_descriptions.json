{
  "modules": [
    {
      "number": 8,
      "title": "Visual Features for Computer Vision",
      "dropdownTitle": "Computer Vision",
      "body": "While artificial intelligence is applied to a wide range of domains, the applications of AI to computer vision tend to begin with operations that mimic to some degree the receptive fields of early visual neurons. We will explore automated image filtering, convolutions, and feature extraction, comparing and contrasting physiological and machine processes. What is a visual “feature” for computer vision? What are some commonly extracted visual features when using convolutional neural networks? How do “early” feature-detectors in artificial neural networks work? In other words, how does one go from an array of image intensity values to an “early”network layer’s array of feature values?",
      "bgColor": "bg-lightblue",
      "textColor": "text-darkblue",
      "margin": "mr-64",
      "imgSrc": "mod8",
      "path": "computer-vision",
      "active": true,
      "parentModule": ""
    },
    {
      "number": 8.1,
      "title": "Intro to Images and Kernels",
      "dropdownTitle": "Images and Kernels",
      "body": "To begin, we discuss how an image is represented as data so it can be used in computer vision algorithms. We also introduce the kernel, and how it relates to the task of extracting features from images.",
      "bgColor": "bg-darkblue",
      "textColor": "text-white",
      "margin": "ml-64",
      "imgSrc": "kernel",
      "path": "images-and-kernels",
      "active": true,
      "parentModule": "Computer Vision"
    },
    {
      "number": 8.2,
      "title": "Image Blurring: The Gaussian Blur",
      "dropdownTitle": "Gaussian Blur",
      "body": "Here we explore the Gaussian Blur, a popular computer vision technique that blurs an image. It uses a kernel with values obtained from the Gaussian function.",
      "bgColor": "bg-lightblue",
      "textColor": "text-darkblue",
      "margin": "mr-64",
      "imgSrc": "gausBlur",
      "path": "gaussian-blur",
      "active": true,
      "parentModule": "Computer Vision"
    },
    {
      "number": 8.3,
      "title": "Directional Filtering: The Gabor Filter",
      "dropdownTitle": "Gabor Filter",
      "body": "This section explores another computer vision technique called the Gabor Filter, which extracts portions of an image that follow a specific directional pattern.",
      "bgColor": "bg-darkblue",
      "textColor": "text-white",
      "margin": "ml-64",
      "imgSrc": "gabor",
      "path": "gabor-filter",
      "active": true,
      "parentModule": "Computer Vision"
    },
    {
      "number": 8.4,
      "title": "Edge Detection: The Sobel Filter",
      "dropdownTitle": "Sobel Filter",
      "body": "In order to detect an object within an image, we search for edges in the image to give us a sense of the shape of the object. We use the Sobel Filter to detect edges in a particular direction in an image.",
      "bgColor": "bg-offwhite",
      "textColor": "text-darkblue",
      "margin": "mr-64",
      "imgSrc": "sobel",
      "path": "sobel-filter",
      "active": true,
      "parentModule": "Computer Vision"
    },
    {
      "number": 8.5,
      "title": "Histogram of (Oriented) Gradients",
      "dropdownTitle": "Histogram of Gradients",
      "body": "While a Sobel Filter can give us information about edges in a singular direction, we need to know about the edges in all directions simultaneously to fully understand the shape of the image. The Histogram of Gradients allows us to collect the edges in all different directions.",
      "bgColor": "bg-darkblue",
      "textColor": "text-white",
      "margin": "ml-64",
      "imgSrc": "hog",
      "path": "histogram-of-gradients",
      "active": true,
      "parentModule": "Computer Vision"
    },
    {
      "number": 9,
      "title": "Recognition as a Classification Problem",
      "dropdownTitle": "Classification",
      "body": "Once features have been detected and, perhaps combined into “higher-order features”, machine vision algorithms are often tasked to perform classification–that is, to determine what an array of features is “of”. Does this bundle of features in an image indicate the presence of a dog? Does that bundle of features over there indicate a cat? A set of features can be thought of as a location in a “state space”. Nearby locations in state space tend to correspond to similar objects or scenes. Features of many dogs of the same breed may form a “cluster” in state space. We will explore clusters of features in some simple state spaces and begin to ask how different “naturally occurring” clusters (corresponding to dogs and cats in our example) might be detected by a machine.",
      "bgColor": "bg-offwhite",
      "textColor": "text-darkblue",
      "margin": "ml-64",
      "imgSrc": "mod9",
      "path": "classification",
      "active": true,
      "parentModule": ""
    },
    {
      "number": 10,
      "title": "Introduction to Machine Learning: Perceptrons",
      "dropdownTitle": "Perceptrons",
      "body": "Today’s remarkable advances in the power of artificial neural networks leverage  foundations laid in 1943 by the McCulloch and Pitts neuron model and Rosenblatt’s 1958 software implementation of the first perceptron. We will examine the architecture and functions of the simplest trainable pattern classifier.This classifier is so simple, in fact, that it cannot effectively separate clusters that are not “linearly separable”. Two clusters in a two-dimensional state space that cannot be separated by a single straight line are examples of non-linearly separable classes. What does the perceptron do when confronted with a data-set that is not linearly separable?",
      "bgColor": "bg-darkblue",
      "textColor": "text-white",
      "margin": "mr-64",
      "imgSrc": "mod10",
      "path": "perceptrons",
      "active": false,
      "parentModule": ""
    },
    {
      "number": 11,
      "title": "Multi-layer Perceptrons & Backpropagation",
      "dropdownTitle": "Neural Networks",
      "body": "The problem of trying to separate clusters that are not linearly separable has been known for more than half a century, and many variations of multi-layer perceptrons continue to be developed to address and overcome limitations of earlier approaches. Multi-layered artificial neural networks are often said to have “hidden layers” where features are iteratively “weighted” in various ways until a desired classification performance is reached. We will consider a simple example of how hidden layers help to solve the “exclusive-OR problem” and explore the “credit assignment problem.” How does an algorithm know which weights to change and by how much, in order to promote learning for improved classification by a neural network?",
      "bgColor": "bg-offwhite",
      "textColor": "text-darkblue",
      "margin": "ml-64",
      "imgSrc": "mod11",
      "path": "neural-nets",
      "active": false,
      "parentModule": ""
    }
  ]
}